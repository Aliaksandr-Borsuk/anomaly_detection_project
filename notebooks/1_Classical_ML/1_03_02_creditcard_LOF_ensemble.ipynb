{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a903f4-00c0-4765-8b5c-bc1033c03d4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Мысль - лучшая модель lof обучается только на небольшой части выборки.\n",
    "**Идея** - обучим модель на разных выборках получим коллективное предсказание и снизим variance.\n",
    "- Ансамблирование - наше всё!  :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b78c68-27f3-4f80-9899-d5b13c9f4af7",
   "metadata": {},
   "source": [
    "## Нюанс.\n",
    "Данные имеют временные метки. \n",
    "Соответственно, split обязательно должен быть по времени.\n",
    "- и при разделении на train - test\n",
    "- и при кроссвалидации.\n",
    "  \n",
    "Так же и нормализовывать данные необходимо после разбиения.\n",
    "- однако в этом случае качество моделей падает ниже плинтуса, то на эту утечку пока забью...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7d8e8-8c1e-4190-96c6-98e6f147d8d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e413e3-dc9a-4c57-9575-85303c7e5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ParameterGrid\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, \n",
    "                            precision_recall_curve, auc, confusion_matrix)\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Конфигурация\n",
    "RANDOM_STATE = 42\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266e2cf-ccaa-43e1-908e-707f5b9e877b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead18bf6-ae6f-47bc-8e9e-5786e0b23ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск пути от текущего файла в папку \n",
    "# anomaly_detection_project\\data\\raw где лежит датасет\n",
    "def find_path_within_project(project_name, path_to_data):\n",
    "    current_path = os.getcwd()   # путь к текущему файлу\n",
    "  \n",
    "    while True:\n",
    "        # Проверяем, находится ли проект в текущем каталоге\n",
    "        # если найден лепим и возвращаем нужный путь к данным\n",
    "        if project_name in os.listdir(current_path):\n",
    "            # Строим путь до нужной папки внутри проекта\n",
    "            return os.path.join(current_path, project_name, path_to_data)\n",
    "        \n",
    "        parent_path = os.path.dirname(current_path)\n",
    "        \n",
    "        if parent_path == current_path:\n",
    "            raise FileNotFoundError(f\"Проект '{project_name}' не найден в родительских каталогах.\")\n",
    "        # если проекта нет поднимаемся выше\n",
    "        current_path = parent_path\n",
    "\n",
    "# Получаем путь\n",
    "full_path_to_cc_1_02_00 = find_path_within_project(\n",
    "    \"anomaly_detection_project\", \n",
    "    os.path.join(\"data\", \"raw\",'creditcard_1_02_00.csv' )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd9050a-73ab-44a6-837f-a45e1a14a1cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Размер данных: 284807 строк, 35 столбцов\n",
      "Распределение классов:\n",
      "Class\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Данные. Первые строки:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Time_hour</th>\n",
       "      <th>Time_day</th>\n",
       "      <th>Time_abs_hour</th>\n",
       "      <th>Amount_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.014760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.305626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.939276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.824306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.262539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V25       V26       V27       V28  Amount  \\\n",
       "0  0.098698  0.363787  ...  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1  0.085102 -0.255425  ...  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2  0.247676 -1.514654  ... -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3  0.377436 -1.387024  ...  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4 -0.270533  0.817739  ... -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "\n",
       "   Class  Time_hour  Time_day  Time_abs_hour  Amount_log  \n",
       "0      0        0.0       0.0            0.0    5.014760  \n",
       "1      0        0.0       0.0            0.0    1.305626  \n",
       "2      0        0.0       0.0            0.0    5.939276  \n",
       "3      0        0.0       0.0            0.0    4.824306  \n",
       "4      0        0.0       0.0            0.0    4.262539  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список колонок без PCA: \n",
      " Time Amount Class Time_hour Time_day Time_abs_hour Amount_log\n"
     ]
    }
   ],
   "source": [
    "# файл creditcard_1_02_00.csv лежит в папке data/raw/\n",
    "# там добавлены новые колонки времени и суммы \n",
    "# print(f\"Загрузка данных из {full_path}\")\n",
    "df = pd.read_csv(full_path_to_cc_1_02_00)\n",
    "\n",
    "# посмотрим ка\n",
    "print(\"\\n\")\n",
    "print(f\"Размер данных: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "print(f\"Распределение классов:\\n{df['Class'].value_counts(normalize=True)}\")\n",
    "print(f\"\\nДанные. Первые строки:\")\n",
    "display(df.head())\n",
    "print(\"Список колонок без PCA: \\n\", *df.columns[~df.columns.str.startswith('V')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb943cec-967c-40ee-8fda-9ea3c6866654",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Выделение test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46949981-1217-4710-b05c-9fb4577a74a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 47.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# колонка для сплита\n",
    "time_column = 'Time_abs_hour'\n",
    "df[time_column].min(), df[time_column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28ed75a-c8ec-41b3-8375-68a9e1706b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy checking: \n",
      " train min 0.0, train max 39.0\n",
      " test min 40.0, test max 47.0\n",
      "\n",
      "Отрезали тестовую выборку.\n",
      "Размеры train:(224865, 35) test: (59942, 35) .\n"
     ]
    }
   ],
   "source": [
    "# Выделим для теста последние 8 часов\n",
    "def get_train_test(df, col, train_finish,\n",
    "                   train_start = 0, test_finish = 0, gap = 0,\n",
    "                   easy_check =True):\n",
    "    '''делим df на train и test \n",
    "        - gap -зазор между train и test (возможно и не пригодиццо)\n",
    "    '''\n",
    "    # определяем test_start и test_finish\n",
    "    if test_finish == 0:\n",
    "        test_finish = df[col].max()\n",
    "    test_start = train_finish + gap + 1\n",
    "    df_train = df[(df[col] >= train_start) & (df[col] <= train_finish)]\n",
    "    df_test =  df[(df[col] >= test_start) & (df[col] <= test_finish)]\n",
    "    if  easy_check:\n",
    "        print(\"easy checking: \\n\",\n",
    "              f\"train min {df_train[col].min()}, train max {df_train[col].max()}\\n\" , \n",
    "              f\"test min {df_test[col].min()}, test max {df_test[col].max()}\")\n",
    "    return df_train, df_test\n",
    "    \n",
    "\n",
    "# колонка для сплита\n",
    "time_column = 'Time_abs_hour'\n",
    "# лимит трайна\n",
    "train_finish = df[time_column].max() - 8\n",
    "\n",
    "df_train, df_test = get_train_test(df, time_column , train_finish)\n",
    "print(\"\\nОтрезали тестовую выборку.\")\n",
    "print(f\"Размеры train:{df_train.shape} test: {df_test.shape} .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2a74e-6113-4477-876d-f57fd5039222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Кросс валидация + обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7642cd-d4d6-44d2-b07a-124bc4cf6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# домашняя кросс валидация с учётом временных меток\n",
    "# возвращает позиционные индексы\n",
    "class my_Time_Series_Fold_for_df:\n",
    "    def __init__(self):\n",
    "        self.folds = []\n",
    "\n",
    "    def split(self, df, time_col, n_folds, rolling_window= True,  talker = True):\n",
    "        '''rolling_window - тактика формирования train'''\n",
    "\n",
    "        self.talker = talker\n",
    "        # Получаем временные метки\n",
    "        time_values = df[time_col]\n",
    "        min_time = time_values.min()\n",
    "        max_time = time_values.max()\n",
    "        ############\n",
    "        print(min_time, max_time)\n",
    "\n",
    "        # Общая продолжительность временного интервала\n",
    "        total_time = max_time + 1 - min_time\n",
    "\n",
    "        # Границы фолдов\n",
    "        fold_time_limits = [total_time*i/(n_folds+1) + min_time for i in range(n_folds+2)]\n",
    "        if self.talker:\n",
    "            print(\"\\n*** my_Time_Series_Fold_for_df ***\\n\")\n",
    "            print(fold_time_limits)\n",
    "\n",
    "        for i in range(n_folds):\n",
    "            # Временные границы обучающей выборки\n",
    "            # в зависимости от стратегии\n",
    "            train_time_start = fold_time_limits[\n",
    "                    i if rolling_window else 0\n",
    "                ]\n",
    "            train_time_end =  fold_time_limits[i+1]\n",
    "\n",
    "            # Временные границы тестовой выборки\n",
    "            # test_time_start = train_time_end\n",
    "            test_time_end = fold_time_limits[i+2]\n",
    "\n",
    "            # Формируем обучающую и тестовую выборки\n",
    "            train_idx = df[(df[time_col] >= train_time_start) & \n",
    "                            (df[time_col] < train_time_end)].index\n",
    "\n",
    "            test_idx = df[(df[time_col] >= train_time_end) & \n",
    "                            (df[time_col] < test_time_end)].index\n",
    "\n",
    "            # Преобразуем метки в позиции\n",
    "            train_pos = df.index.get_indexer(train_idx)\n",
    "            test_pos = df.index.get_indexer(test_idx)\n",
    "            if self.talker:\n",
    "                print(f\"Номер фолда {i+1}\")\n",
    "                print(f\"Размер train: {len(train_pos)}, test: {len(test_pos)}\")\n",
    "\n",
    "            # Добавляем пары индексов в список фолдов\n",
    "            self.folds.append((train_pos, test_pos))\n",
    "\n",
    "        return self.folds\n",
    "\n",
    "time_separator = my_Time_Series_Fold_for_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d404468-934a-4142-a4f4-483b7412cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# домашний unsupervised GridSearch для ocsvm, Isolation Forest, LOF\n",
    "class my_GridSearchCV_for_df:\n",
    "    '''\n",
    "        Подбор гиперпараметров модели\n",
    "        Разрешённые модели OCSVM, Isolation Forest, LOF(novelty = True)\n",
    "        обучение возможно только на нормальных объектах или на всех\n",
    "        cv - стратегия кросс валидации класс который формирует позиции \n",
    "        X_train, y_train, X_test,  y_test по временной колонке\n",
    "        n_samples - определяет сколько сэмплировать объектов для обучения,\n",
    "        ибо для lof и для OCSVM размер выборки критичен\n",
    "        drop_columns - колонки которые не учавствуют в обучении и предсказании\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, model, param_grid, cv = time_separator,  scoring = f1_score,\n",
    "                 time_col = time_column, n_folds = 3, drop_columns = list(),\n",
    "                 normalizer = None, n_samples = None, talker = True,\n",
    "                 unsupervised = True, random_state=None):\n",
    "\n",
    "        self.estimator = model\n",
    "        self.drop_columns = drop_columns\n",
    "        self.unsupervised = unsupervised\n",
    "        self.param_grid = list(ParameterGrid(param_grid))   # dict словарь параметров\n",
    "        self.cv = cv                                        # стратегия кроссвалидации\n",
    "        self.scoring = scoring                              # ф-я оценки (y_true, y_pred) -> float, например f1_score\n",
    "        self.time_col = time_col\n",
    "        self.n_folds = n_folds\n",
    "        self.normalizer = normalizer                         # LOF, OCSVM хотят нормализа\n",
    "        self.n_samples = n_samples\n",
    "        self.talker = talker\n",
    "        self.random_state = random_state\n",
    "                        # стратегия кросс валидации и обучения итоговой модели\n",
    "\n",
    "    def fit(self, X, y, rolling_window = True):\n",
    "        \"\"\" Перебирает все комбинации параметров и заполняет cv_results_.\n",
    "            - X - df\n",
    "            - y - Series\n",
    "            - rolling_window - тактика формирования train и обучения\n",
    "        \"\"\"\n",
    "\n",
    "        # структуры для хранения результатов\n",
    "        all_params = []\n",
    "        mean_test_scores = []\n",
    "        std_test_scores = []\n",
    "\n",
    "        # получаем разбиение по фолдам\n",
    "        train_test_positions = self.cv.split(X, self.time_col,\n",
    "                                             self.n_folds, rolling_window, self.talker)\n",
    "        \n",
    "        # добавляем в удаляемые колонку по которой делили\n",
    "        self.drop_columns.append(self.time_col)\n",
    "\n",
    "        # полный перебор\n",
    "        for params in self.param_grid:\n",
    "            test_scores = []\n",
    "\n",
    "            # переделано под пандас получаем позици строк , не индексы!!!\n",
    "            for train_pos, test_pos in train_test_positions:\n",
    "                X_train, y_train = X.drop(self.drop_columns, axis=1).iloc[train_pos] , y.iloc[train_pos]\n",
    "                X_test,  y_test  = X.drop(self.drop_columns, axis=1).iloc[test_pos] ,  y.iloc[test_pos]\n",
    "\n",
    "                # если нужно стандартизировать выборку для обучения LOF, OCSVM\n",
    "                # возможно это нужно делать после усечения train но пока так...\n",
    "                if self.normalizer is not None:\n",
    "                    # train\n",
    "                    X_sc = self.normalizer.fit_transform(X_train)\n",
    "                    # обратно в df\n",
    "                    X_train = pd.DataFrame(X_sc, columns=X_train.columns, index=X_train.index)\n",
    "                    # test\n",
    "                    X_sc = self.normalizer.transform(X_test)\n",
    "                    # обратно в df для тест наверное не нужно ...\n",
    "                    X_test = pd.DataFrame(X_sc, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "                # если нужно\n",
    "                if self.unsupervised:\n",
    "                    # в train только нормальные объекты\n",
    "                    X_train = X_train[y_train == 0]\n",
    "\n",
    "                # если нужно уменьшить выборку для обучения LOF, OCSVM\n",
    "                if self.n_samples is not None:\n",
    "                    np.random.seed(self.random_state)  # фиксируем генератор\n",
    "                    indices = np.random.choice(len(X_train), size=self.n_samples, replace=False)\n",
    "                    X_train = X_train.iloc[indices]\n",
    "\n",
    "                # рожаем модель\n",
    "                model = clone(self.estimator).set_params(**params)\n",
    "                model.fit(X_train)\n",
    "\n",
    "                # предсказания на test с инверсией\n",
    "                y_pred = np.where(model.predict(X_test) == -1, 1, 0)\n",
    "                test_scores.append(self.scoring(y_test, y_pred))\n",
    "\n",
    "            all_params.append(params)\n",
    "            mean_test_scores.append(np.mean(test_scores))\n",
    "            std_test_scores.append(np.std(test_scores))\n",
    "            if self.talker:\n",
    "                print(f\"\\nПараметры {params}\")\n",
    "                print(f\"mean_scores {mean_test_scores[-1]}\")\n",
    "                print(f\"std {std_test_scores[-1]}\")\n",
    "\n",
    "        # собираем cv_results_\n",
    "        # можно докинуть потом 'rank_test_score', \n",
    "        #'split0_test_score', 'split1_test_score', ...: оценки на каждом фолде\n",
    "        # 'mean_fit_time', 'mean_score_time': время обучения и оценки\n",
    "        cv_results = {\n",
    "            'params': all_params,\n",
    "            'mean_test_score': np.array(mean_test_scores),\n",
    "            'std_test_score':  np.array(std_test_scores),\n",
    "        }\n",
    "\n",
    "        # сохраняем результаты\n",
    "        self.cv_results_  = cv_results\n",
    "\n",
    "        # выбираем лучший индекс по mean_test_score\n",
    "        best_idx = np.argmax(cv_results['mean_test_score'])\n",
    "        self.best_params_  = all_params[best_idx]\n",
    "        self.best_score_   = cv_results['mean_test_score'][best_idx]\n",
    "        self.best_estimator_ = clone(self.estimator).set_params(**self.best_params_)\n",
    "\n",
    "        # обучаем лучший на всей выборке кроме колонок которые нужно дропнуть\n",
    "        X = X.drop(self.drop_columns, axis=1)\n",
    "        \n",
    "        # если тактика rolling_window обучаем только на данных последнего фолда\n",
    "        if rolling_window:\n",
    "            X, y  = X.iloc[test_pos] ,  y.iloc[test_pos]\n",
    "            \n",
    "        # если нужно стандартизировать выборку для обучения LOF, OCSVM\n",
    "        # возможно это нужно делать после усечения train но пока так...\n",
    "        if self.normalizer is not None:\n",
    "            X_sc = self.normalizer.fit_transform(X)\n",
    "            # обратно в df\n",
    "            X = pd.DataFrame(X_sc, columns=X.columns, index=X.index)    \n",
    "            \n",
    "        # только нормальные)\n",
    "        if self.unsupervised:\n",
    "            X = X[y==0]\n",
    "\n",
    "        # если нужно уменьшить выборку для обучения LOF, OCSVM\n",
    "        if self.n_samples is not None:\n",
    "            indices = np.random.choice(len(X), size=self.n_samples*2, replace=False)\n",
    "            X = X.iloc[indices]\n",
    "        \n",
    "        self.best_estimator_.fit(X)\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает метки для X, используя best_estimator_.\n",
    "        Возвращает 1 для нормальных и -1 для аномалий, как и ocsvm\n",
    "        \"\"\"\n",
    "        self.check_best_estimator()\n",
    "\n",
    "        X = X.drop(self.drop_columns, axis=1)\n",
    "        # если нужно стандартизироввали выборку для обучения LOF, OCSVM то\n",
    "        if self.normalizer is not None:\n",
    "            X = self.normalizer.transform(X) \n",
    "            \n",
    "        return self.best_estimator_.predict(X)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Возвращает значение decision_function от best_estimator_.\n",
    "        или \n",
    "        \"\"\"\n",
    "        self.check_best_estimator()\n",
    "\n",
    "        X = X.drop(self.drop_columns, axis=1)\n",
    "        # если нужно стандартизировали выборку для обучения LOF, OCSVM\n",
    "        if self.normalizer is not None:\n",
    "            X = self.normalizer.transform(X) \n",
    "            \n",
    "        return self.best_estimator_.decision_function(X)\n",
    "\n",
    "    def check_best_estimator(self):\n",
    "        \"\"\"\n",
    "        проверка наличия обученого моделя\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'best_estimator_'):\n",
    "            raise AttributeError(\"Нужно сначала вызвать .fit()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a770258f-ac1c-4554-b2bb-01e784988d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для предсказания оставляем только колонки с PCA признаками и Amount_log ???\n",
    "# Предобработка\n",
    "drop_cols = ['Class']\n",
    "\n",
    "X = df_train.drop(drop_cols, axis=1)\n",
    "y = df_train['Class']\n",
    "\n",
    "X_test = df_test.drop(drop_cols, axis=1)\n",
    "y_test = df_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5a7059-d045-4725-b801-b4c0e6deccfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные содержат колонки:  Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Time_hour', 'Time_day', 'Time_abs_hour', 'Amount_log'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Данные содержат колонки: \", X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294f1c53-27fd-4408-947a-bf900a0622c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для предсказания ни временные колонки ни величина транзакций нам не нужны\n",
    "# кроме PCA колонок оставляем только  'Time_abs_hour' по ней будем бить на фолды\n",
    "unnecessary_cols = ['Time', 'Amount', 'Time_hour', 'Time_day', 'Amount_log'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d350be-58fa-40f2-969e-94f59fbbbf8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## пробуем ансамбль из нескольких lof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174356aa-970c-4034-beaa-2718bd21e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ansamble_Models:\n",
    "    def __init__(self, model, n_models,\n",
    "                 grid_params, time_column, \n",
    "                 n_folds, n_samples, \n",
    "                 drop_columns = unnecessary_cols,\n",
    "                 grid_verbose = True,\n",
    "                 normalizer = None, random_state = RANDOM_STATE):\n",
    "        self.model = model\n",
    "        # переход к нечётному ибо нефик\n",
    "        self.n_models = n_models - n_models % 2 + 1 \n",
    "        self.grid_params = grid_params\n",
    "        self.grid_verbose = grid_verbose\n",
    "        self.time_column = time_column\n",
    "        self.n_folds = n_folds\n",
    "        self.n_samples = n_samples\n",
    "        self.normalizer = normalizer\n",
    "        self.drop_columns = drop_columns\n",
    "        self.random_state = random_state   \n",
    "\n",
    "\n",
    "    def fit(self, X, y, rolling_window=False, random_shift = 2 ):\n",
    "        self.models_ = []\n",
    "        for i in range(self.n_models):\n",
    "            grid = my_GridSearchCV_for_df(\n",
    "                        model=self.model,\n",
    "                        param_grid = self.grid_params, \n",
    "                        time_col = self.time_column,\n",
    "                        n_folds = self.n_folds,\n",
    "                        n_samples = self.n_samples,\n",
    "                        normalizer = self.normalizer,\n",
    "                        drop_columns = self.drop_columns,\n",
    "                        random_state = self.random_state + i*random_shift,\n",
    "                        talker= self.grid_verbose\n",
    "                    )\n",
    "            grid.fit(X, y, rolling_window=rolling_window)\n",
    "            self.models_.append(grid)\n",
    "            \n",
    "            print('------------------------------------------')\n",
    "            print( f'Лучшие параметры {i+1}_ой модели: {grid.best_params_}')\n",
    "            print( f'Лучшая оценка {i+1}_ой модели: {grid.best_score_}')\n",
    "            print('------------------------------------------\\n')\n",
    "\n",
    "    def check_models_(self):\n",
    "        \"\"\"\n",
    "        проверка наличия обученого моделя\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'models_'):\n",
    "            raise AttributeError(\"Нужно сначала вызвать .fit()\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает метки для X, используя набор моделей.\n",
    "        Возвращает 1 для нормальных и -1 для аномалий,\n",
    "        \"\"\"\n",
    "        self.check_models_()\n",
    "        \n",
    "        predicts = []\n",
    "        for grid  in self.models_:\n",
    "            predicts.append(grid.predict(X))\n",
    "        \n",
    "        predict = np.sign(\n",
    "            np.sum(predicts, axis = 0)\n",
    "        )\n",
    "        return predict\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Возвращает значение decision_function от models_.\n",
    "        или \n",
    "        \"\"\"\n",
    "        self.check_models_()\n",
    "        # если нужно стандартизировали выборку для обучения LOF, OCSVM\n",
    "        if self.normalizer is not None:\n",
    "            X = self.normalizer.transform(X) \n",
    "\n",
    "        decision_funcs = []\n",
    "        for grid in self.models_:\n",
    "            decision_funcs.append(grid.decision_function(X))\n",
    "        dec_func = StandardScaler().fit_transform(np.array(decision_funcs).T).T\n",
    "            \n",
    "        return np.mean(dec_func, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceaa2823-9d51-4e35-be63-a6fd91e23bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 1_ой модели: {'contamination': 0.001, 'n_neighbors': 15}\n",
      "Лучшая оценка 1_ой модели: 0.5135204031991282\n",
      "------------------------------------------\n",
      "\n",
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 2_ой модели: {'contamination': 0.001, 'n_neighbors': 15}\n",
      "Лучшая оценка 2_ой модели: 0.528279878450116\n",
      "------------------------------------------\n",
      "\n",
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 3_ой модели: {'contamination': 0.001, 'n_neighbors': 15}\n",
      "Лучшая оценка 3_ой модели: 0.3906518630818358\n",
      "------------------------------------------\n",
      "\n",
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 4_ой модели: {'contamination': 0.001, 'n_neighbors': 15}\n",
      "Лучшая оценка 4_ой модели: 0.37779617323014686\n",
      "------------------------------------------\n",
      "\n",
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 5_ой модели: {'contamination': 0.001, 'n_neighbors': 10}\n",
      "Лучшая оценка 5_ой модели: 0.57550041154454\n",
      "------------------------------------------\n",
      "\n",
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 6_ой модели: {'contamination': 0.001, 'n_neighbors': 15}\n",
      "Лучшая оценка 6_ой модели: 0.44890185723106973\n",
      "------------------------------------------\n",
      "\n",
      "0.0 39.0\n",
      "------------------------------------------\n",
      "Лучшие параметры 7_ой модели: {'contamination': 0.001, 'n_neighbors': 15}\n",
      "Лучшая оценка 7_ой модели: 0.5063515073813936\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Поиск гиперпараметров\n",
    "lof = LocalOutlierFactor(novelty=True)\n",
    "\n",
    "param_lof = {\n",
    "    'n_neighbors': [10, 15],\n",
    "    'contamination': [ 0.001]\n",
    "}\n",
    "\n",
    "grid_lof_models = Ansamble_Models(\n",
    "    model = lof,\n",
    "    n_models = 7,\n",
    "    grid_params = param_lof,\n",
    "    time_column = time_column,\n",
    "    n_folds = 3,\n",
    "    n_samples = 3000, \n",
    "    drop_columns = unnecessary_cols,\n",
    "    normalizer = None,\n",
    "    random_state = RANDOM_STATE,\n",
    "    grid_verbose=False\n",
    ")\n",
    "\n",
    "grid_lof_models.fit(X, y, rolling_window=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6d201d9-8101-4cb5-aa69-587d9c2ce3a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_pr_curve_and_conf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Оценка на train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_pr_curve_and_conf_matrix\u001b[49m(\n\u001b[0;32m      3\u001b[0m     grid_lof_models, \n\u001b[0;32m      4\u001b[0m     X,\n\u001b[0;32m      5\u001b[0m     y,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mКучка LocalOutlierFactor на train\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_pr_curve_and_conf_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Оценка на train\n",
    "plot_pr_curve_and_conf_matrix(\n",
    "    grid_lof_models, \n",
    "    X,\n",
    "    y,'Кучка LocalOutlierFactor на train' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7fb77-6a75-4b71-99b6-a23aa6cf47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка на test\n",
    "plot_pr_curve_and_conf_matrix(\n",
    "    grid_lof_models, X_test,\n",
    "    y_test,'Кучка LocalOutlierFactor на test' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5c3c2-fed1-4923-aa68-994ebf91444b",
   "metadata": {},
   "source": [
    "## 6. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827c909-3691-4d33-88a5-9f7602e4a697",
   "metadata": {},
   "source": [
    "**Датасет**\n",
    "- **Объём**: 284 807 транзакций, 35 признаков.\n",
    "- **Ну очень сильный дисбаланс**: 0,17% транзакций — мошеннические (Class == 1).\n",
    "\n",
    "**Временное разбиение**: данные разделены по `Time_abs_hour`:\n",
    "  - **Train**: 0–39 часов (224 865 строк).  \n",
    "  - **Test**: 40–47 часов (59 942 строк).\n",
    "  \n",
    "**Модель**  \n",
    "- ансамбль **LocalOutlierFactor**  (unsupervised).\n",
    "-  обучались на разных подвыборках данных\n",
    "\n",
    "**Метрики**  | F1   | PR AUC |\n",
    "- **Train**   | 0.66 | 0.65   |\n",
    "- **Test**     | 0.61 | 0.49   |\n",
    "  \n",
    "**Вывод**\n",
    "- Ансамбль **LOF** показал ожидаемое **улучшение качества** за счёт снижения дисперсии **коллектива моделей** относительно одной модели.\n",
    "\n",
    "**Возможные улучшения**\n",
    "- При unsupervised обучении мы игнорим важные данные о целевой переменной в трейне.  Так как эти данные у нас есть нужно попробовать модели классификаци для получения лучшего результата."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b03a34-79e1-4466-906d-37b99cb64f98",
   "metadata": {},
   "source": [
    "## Happy end....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
