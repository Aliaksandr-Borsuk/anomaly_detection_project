#  Anomaly Detection Project  
**Обнаружение мошеннических транзакций с кредитных карт с помощью классических и современных ML/DL методов**

> Цель проекта - разработать эффективную систему детекции аномалий (мошеннических транзакций) на сильно несбалансированных данных (0.17% аномалий)

---

##  Задача и данные
- **Датасет**: European credit card transactions (сентябрь 2013 г.), 284 807 транзакций, 31 признак
- **Ключевые особенности**:
  - Крайний дисбаланс классов: 99.83% нормальных транзакций, 0.17% мошеннических
  - Признаки V1-V28 получены через PCA (из-за требований конфиденциальности)
  - Временные метки позволяют учитывать динамику транзакций
- **Сплит по времени**:
  - Train: 0–39 часов (224 865 записей)
  - Test: 40–47 часов (59 942 записи)
- **Метрики оценки**: Precision, Recall, F1-score, PR-AUC (приоритет из-за дисбаланса классов)

---

##  Проведенные эксперименты и результаты

###  Базовые статистические методы
- **Z-score и IQR** на синтетических данных
- **Вывод**: Работают только при одном кластере нормальных данных, неэффективны при сложных распределениях

### Классические методы детекции аномалий (unsupervised)
- **Isolation Forest**:
  - Лучший результат: F1=0.03 на тесте
  - Проблема: плохо обобщает на данные с динамикой
  
- **Local Outlier Factor (LOF)**:
  - С одним экземпляром: F1=0.53 на тесте
  - Ансамбль из 7 моделей: F1=0.60 на тесте
  - Проблема: требует подвыборки данных из-за вычислительной сложности

- **One-Class SVM**:
  - Лучший результат: F1=0.21 на тесте
  - Проблема: сильное переобучение и низкая обобщающая способность

### Feature Engineering
- **Rolling statistics** (скользящие окна по времени)
- **Добавление временных признаков** (часы, дни)
- **Вывод**: ухудшили качество всех unsupervised моделей, так как мошенничество — аномалия поведения конкретных пользователей, а не общего трафика

### Методы с учителем (supervised)
- **Random Forest**:
  - F1=0.79, PR-AUC=0.80
  - Сильная сторона: хорошая обобщающая способность при дисбалансе классов

- **CatBoost + Optuna**:
  - F1=0.82, PR-AUC=0.82
  - Precision=0.96 - минимальное число ложных срабатываний
  - Калибровка порога улучшила F1 с 0.8209 до 0.8235

### Нейросетевые подходы
- **Простая полносвязная сеть (Simple NN)**:
  - F1=0.80, PR-AUC=0.81
  - Подбор гиперпараметров через Optuna существенно улучшил качество

- **TabNet**:
  - F1=0.82, PR-AUC=0.79
  - Эффективная работа с табличными данными и интерпретируемость признаков

- **TabMixer (упрощённый MLP-Mixer)**:
  - F1=0.79, PR-AUC=0.81
  - Подход, вдохновлённый компьютерным зрением, показал хорошую эффективность на табличных данных

- **LSTM**:
  - F1=0.80, PR-AUC=0.70
  - Проблема: низкое качество из-за отсутствия разделения по пользователям/картам

- **Transformer**:
  - F1=0.78, PR-AUC=0.81
  - Лучшие результаты при длине окна seq_len=17
  - Показал преимущество перед LSTM в обработке временных паттернов

---

##  Сравнение лучших моделей
| Модель | Precision | Recall | F1 | PR-AUC |
|--------|-----------|--------|-----|--------|
| **CatBoost + Optuna** | **0.96** | 0.71 | **0.82** | **0.82** |
| **TabNet** | 0.89 | **0.75** | 0.82 | 0.79 |
| **TabMixer** | 0.96 | 0.68 | 0.79 | 0.81 |
| **Simple NN** | 0.90 | 0.71 | 0.80 | 0.81 |
| **Transformer** | 0.86 | 0.71 | 0.78 | 0.81 |
| **LSTM** | 0.88 | 0.74 | 0.80 | 0.70 |
| **LOF (ансамбль)** | 0.55 | 0.68 | 0.60 | 0.51 |

>  **Ключевой инсайт**: Supervised-подходы (CatBoost, TabNet) кардинально превосходят unsupervised-методы при наличии размеченных данных.

---

##  Как запустить
1. **Требования**:
   - Python 3.10.11
   - Poetry 1.8.2
   - Jupyter Lab 4.4.4
   - GPU для нейросетевых моделей (рекомендуется)

2. **Установка**:
```bash
git clone https://github.com/Aliaksandr-Borsuk/anomaly_detection_project.git
cd anomaly_detection_project
poetry install
poetry shell
```

3. **Работа с проектом**:
   - Все ноутбуки находятся в корневой директории
   - Предобработанные данные в `data/raw/`
   - Каждый ноутбук автономен и содержит полный пайплайн: от загрузки данных до визуализации результатов
   - Для запуска в Google Colab используйте ссылки в ноутбуках

---

##  Технологический стек
- **Язык**: Python 3.10
- **Библиотеки**:
  - scikit-learn, pandas, numpy, matplotlib, seaborn
  - catboost, optuna, pytorch, pytorch_tabnet
  - imbalanced-learn
- **Инструменты**:
  - Poetry для управления зависимостями
  - Jupyter Lab для интерактивной работы
  - Google Colab для GPU-ускорения
- **Методологии**:
  - Временное разбиение (time-series split)
  - Подбор гиперпараметров через Optuna
  - Калибровка порога классификации
  - Борьба с дисбалансом классов

---

##  Выводы
1. **Supervised > Unsupervised**: При наличии аннотированных данных методы с учителем (CatBoost, TabNet) существенно превосходят unsupervised-подходы
2. **Важность метрик**: PR-AUC и F1 более информативны, чем accuracy, в условиях сильного дисбаланса классов
3. **Критичность подбора порога**: Корректная калибровка порога классификации может улучшить F1 на 5-10%
4. **Сложность не всегда лучше**: CatBoost с подобранными гиперпараметрами превосходит многие глубокие архитектуры
5. **Проблема временных данных**: Для задачи детекции мошенничества критически важно учитывать поведение на уровне отдельных пользователей/карт

> **Рекомендация для продакшена**: Использовать CatBoost или ансамбль из CatBoost + TabNet с калиброванным порогом для минимизации ложных срабатываний при сохранении высокого Recall.

---

##  Лицензия
MIT


---

**Спасибо за внимание!** Этот проект демонстрирует эволюцию подходов к решению реальной бизнес-задачи - детекции мошенничества - от базовых статистических методов до современных архитектур глубокого обучения.






